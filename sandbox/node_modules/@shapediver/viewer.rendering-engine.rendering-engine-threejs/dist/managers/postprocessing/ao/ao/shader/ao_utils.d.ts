export declare const ao_utils = "\nuniform mat4 projectionMatrixInverse;\nuniform sampler2D normalTexture;\n\nin mat4 viewMatrixInverse;\n\nvec3 computeWorldPosition(float depth, vec2 coord) {\n    // Convert screen coordinates to normalized device coordinates (NDC)\n    vec2 ndc = coord * 2.0 - 1.0;\n\n    // Convert depth to clip space z\n    float z = depth * 2.0 - 1.0;\n\n    // Create clip space position\n    vec4 clipSpacePosition = vec4(ndc, z, 1.0);\n\n    // Transform to view space\n    vec4 viewSpacePosition = projectionMatrixInverse * clipSpacePosition;\n\n    // Perspective division\n    viewSpacePosition /= viewSpacePosition.w;\n\n    // Transform to world space using the full inverse view matrix\n    vec4 worldSpacePosition = viewMatrixInverse * viewSpacePosition;\n\n    return worldSpacePosition.xyz;\n}\n\nvec3 computeNormal(vec2 vUv) {\n    vec2 size = vec2(textureSize(depthTexture, 0));\n    ivec2 p = ivec2(vUv * size);\n    float c0 = texelFetch(depthTexture, p, 0).x;\n    float l2 = texelFetch(depthTexture, p - ivec2(2, 0), 0).x;\n    float l1 = texelFetch(depthTexture, p - ivec2(1, 0), 0).x;\n    float r1 = texelFetch(depthTexture, p + ivec2(1, 0), 0).x;\n    float r2 = texelFetch(depthTexture, p + ivec2(2, 0), 0).x;\n    float b2 = texelFetch(depthTexture, p - ivec2(0, 2), 0).x;\n    float b1 = texelFetch(depthTexture, p - ivec2(0, 1), 0).x;\n    float t1 = texelFetch(depthTexture, p + ivec2(0, 1), 0).x;\n    float t2 = texelFetch(depthTexture, p + ivec2(0, 2), 0).x;\n    float dl = abs((2.0 * l1 - l2) - c0);\n    float dr = abs((2.0 * r1 - r2) - c0);\n    float db = abs((2.0 * b1 - b2) - c0);\n    float dt = abs((2.0 * t1 - t2) - c0);\n    vec3 ce = computeWorldPosition(c0, vUv).xyz;\n    vec3 dpdx = (dl < dr) ? ce - computeWorldPosition(l1, (vUv - vec2(1.0 / size.x, 0.0))).xyz\n                          : -ce + computeWorldPosition(r1, (vUv + vec2(1.0 / size.x, 0.0))).xyz;\n    vec3 dpdy = (db < dt) ? ce - computeWorldPosition(b1, (vUv - vec2(0.0, 1.0 / size.y))).xyz\n                          : -ce + computeWorldPosition(t1, (vUv + vec2(0.0, 1.0 / size.y))).xyz;\n    return normalize(cross(dpdx, dpdy));\n}\n\nbool areDepthsOnSamePlane(\n    float depth1, \n    float depth2, \n    vec2 coord1, \n    vec2 coord2,\n    vec3 planeNormalScreenSpace, \n    float epsilon\n) {\n    // Reconstruct world positions\n    vec3 worldPos1 = computeWorldPosition(depth1, coord1);\n    vec3 worldPos2 = computeWorldPosition(depth2, coord2);\n\n    // Compute the vector between the two positions\n    vec3 pointVector = worldPos2 - worldPos1;\n\n    if (length(pointVector) < 1e-6) {\n        return true; // Indicates invalid inputs\n    }\n\n    // Compute the normal in world space\n    vec3 planeNormal = mat3(viewMatrixInverse) * planeNormalScreenSpace;\n\n    // Check if the vector is orthogonal to the plane normal\n    return abs(dot(pointVector, planeNormal)) < epsilon;\n}\n\nvec3 getUnpackedNormal(vec2 uv) {\n    return normalize(textureLod(normalTexture, uv, 0.).xyz * 2.0 - 1.0);\n}\n";
//# sourceMappingURL=ao_utils.d.ts.map